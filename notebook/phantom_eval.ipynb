{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import json\n",
    "\n",
    "\n",
    "def tb_get(path, tag, step_cutoff):\n",
    "    # read tensorboard scalar data\n",
    "\n",
    "    ea = event_accumulator.EventAccumulator(path, size_guidance={\"scalar\": 0})\n",
    "    ea.Reload()\n",
    "    scalar_tensor = ea.Scalars(tag)\n",
    "    target = min(step_cutoff, len(scalar_tensor) - 1)\n",
    "\n",
    "    return scalar_tensor[target].value\n",
    "\n",
    "\n",
    "def check_metrics(tag, folder, key, step):\n",
    "    asr_cnt = 0\n",
    "    retrieved_cnt = 0\n",
    "    retrieved_idx = []\n",
    "    llm_loss = 0\n",
    "    retriever_loss = 0\n",
    "    optimize_idx = []\n",
    "\n",
    "    try:\n",
    "        asr_cnt = tb_get(f\"{folder}\", \"test/called\", step)\n",
    "        retrieved_cnt = tb_get(f\"{folder}\", \"test/retrieved\", step)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        llm_loss = tb_get(f\"{folder}\", \"loss/decoder\", step)\n",
    "        retriever_loss = tb_get(f\"{folder}\", \"loss/encoder\", step)\n",
    "        ea = event_accumulator.EventAccumulator(folder, size_guidance={\"tensors\": 0})\n",
    "        ea.Reload()\n",
    "        retrieved_idx = ea.Tensors(\"retrieved_idxs/text_summary\")\n",
    "        retrieved_idx = json.loads(\n",
    "            retrieved_idx[step].tensor_proto.string_val[0].decode(\"utf-8\")\n",
    "        )\n",
    "        optimize_idx = ea.Tensors(\"success_idxs/text_summary\")\n",
    "        optimize_idx = json.loads(\n",
    "            optimize_idx[step].tensor_proto.string_val[0].decode(\"utf-8\")\n",
    "        )\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return {\n",
    "        \"asr_cnt\": asr_cnt,\n",
    "        \"retrieved_cnt\": retrieved_cnt,\n",
    "        \"retrieved_idx\": list(retrieved_idx),\n",
    "        \"llm_loss\": llm_loss,\n",
    "        \"retriever_loss\": retriever_loss,\n",
    "        \"optimize_idx\": list(optimize_idx),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(range(3))\n",
    "objs = 0\n",
    "steps = [4, 8, 16, 32]\n",
    "\n",
    "\n",
    "def fetch_result(cluster=0, obj=0):\n",
    "    base_dir = f\"logs/prag_base_dq/tb/prag_base_dq.cluster_{cluster}_obj_{obj}\"\n",
    "    v2_dir = f\"logs/prag_v2_dq/tb/prag_v2_dq.cluster_{cluster}_obj_{obj}\"\n",
    "\n",
    "    non_optimize_idxs = set(\n",
    "        check_metrics(\"phantom_base_dq\", base_dir, \"test/called\", 256 // 4)[\n",
    "            \"optimize_idx\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    baseline_asr = []\n",
    "    v2_asr = []\n",
    "    baseline_retrieved = []\n",
    "    v2_retrieved = []\n",
    "    baseline_asr_optimize = []\n",
    "    v2_asr_optimize = []\n",
    "    for step in steps:\n",
    "        result_baseline = check_metrics(\n",
    "            \"phantom_base_dq\", base_dir, \"test/called\", (step + 256) // 4\n",
    "        )\n",
    "        result_v2 = check_metrics(\"phantom_v2_dq\", v2_dir, \"test/called\", step // 4)\n",
    "        print(f\"step: {step}\")\n",
    "        print(\n",
    "            f\"baseline: {result_baseline['asr_cnt']}, {result_baseline['retrieved_cnt']}, {len(result_baseline['retrieved_idx'])}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"v2: {result_v2['asr_cnt']}, {result_v2['retrieved_cnt']}, {len(result_v2['retrieved_idx'])}\"\n",
    "        )\n",
    "        all_idxs = set(range(25))\n",
    "        optimize_idxs = all_idxs - non_optimize_idxs\n",
    "        print(f\"optimize: {optimize_idxs}\")\n",
    "        base_optimize_idxs = set(result_baseline[\"optimize_idx\"]) & optimize_idxs\n",
    "        v2_optimize_set = set(result_v2[\"optimize_idx\"]) & optimize_idxs\n",
    "        print(f\"baseline: {len(base_optimize_idxs)}, {len(optimize_idxs)}\")\n",
    "        print(f\"v2: {len(v2_optimize_set)}, {len(optimize_idxs)}\")\n",
    "\n",
    "        baseline_asr.append(result_baseline[\"asr_cnt\"])\n",
    "        v2_asr.append(result_v2[\"asr_cnt\"])\n",
    "        baseline_retrieved.append(result_baseline[\"retrieved_cnt\"])\n",
    "        v2_retrieved.append(result_v2[\"retrieved_cnt\"])\n",
    "        baseline_asr_optimize.append(len(base_optimize_idxs))\n",
    "        v2_asr_optimize.append(len(v2_optimize_set))\n",
    "\n",
    "    return {\n",
    "        \"baseline_asr\": baseline_asr,\n",
    "        \"v2_asr\": v2_asr,\n",
    "        \"baseline_retrieved\": baseline_retrieved,\n",
    "        \"v2_retrieved\": v2_retrieved,\n",
    "        \"baseline_asr_optimize\": baseline_asr_optimize,\n",
    "        \"v2_asr_optimize\": v2_asr_optimize,\n",
    "        \"optimize_count\": len(optimize_idxs),\n",
    "    }\n",
    "\n",
    "\n",
    "result = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    for obj in objs:\n",
    "        result[(cluster, obj)] = fetch_result(cluster, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.create_sheet(title=f\"cluster_{cluster}\")\n",
    "\n",
    "for cluster in clusters:\n",
    "    ws.append([\"cluster\", cluster])\n",
    "    for obj in objs:\n",
    "        result_obj = result[(cluster, obj)]\n",
    "\n",
    "        # Append result tables\n",
    "        ws.append([\"obj\", obj])\n",
    "        ws.append([\"step\"] + steps)\n",
    "        ws.append([\"baseline_asr\"] + result_obj[\"baseline_asr\"])\n",
    "        ws.append([\"v2_asr\"] + result_obj[\"v2_asr\"])\n",
    "        ws.append([\"baseline_retrieved\"] + result_obj[\"baseline_retrieved\"])\n",
    "        ws.append([\"v2_retrieved\"] + result_obj[\"v2_retrieved\"])\n",
    "        ws.append([\"baseline_asr_optimize\"] + result_obj[\"baseline_asr_optimize\"])\n",
    "        ws.append([\"v2_asr_optimize\"] + result_obj[\"v2_asr_optimize\"])\n",
    "        ws.append([\"optimize_count\", result_obj[\"optimize_count\"]])\n",
    "\n",
    "        # Calculate ASRs\n",
    "        optimize_count = result_obj[\"optimize_count\"]\n",
    "        ws.append([])  # Add a blank row for separation\n",
    "        ws.append([\"ASR\"])\n",
    "        ws.append([\"obj\", obj])\n",
    "        ws.append([\"step\", 0] + steps)\n",
    "        ws.append(\n",
    "            [\"baseline_asr\", 1 - result_obj[\"optimize_count\"] / 25]\n",
    "            + [x / 25 for x in result_obj[\"baseline_asr\"]]\n",
    "        )\n",
    "        ws.append(\n",
    "            [\"v2_asr\", 1 - result_obj[\"optimize_count\"] / 25]\n",
    "            + [x / 25 for x in result_obj[\"v2_asr\"]]\n",
    "        )\n",
    "        ws.append(\n",
    "            [\"baseline_optimize_asr\", 0]\n",
    "            + [x / optimize_count for x in result_obj[\"baseline_asr_optimize\"]]\n",
    "        )\n",
    "        ws.append(\n",
    "            [\"v2_optimize_asr\", 0]\n",
    "            + [x / optimize_count for x in result_obj[\"v2_asr_optimize\"]]\n",
    "        )\n",
    "\n",
    "        ws.append([])\n",
    "        ws.append([])\n",
    "\n",
    "\n",
    "wb.save(\"asr_results.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolattack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
